{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-03T13:54:48.977483Z",
     "iopub.status.busy": "2023-06-03T13:54:48.977173Z",
     "iopub.status.idle": "2023-06-03T13:55:09.681154Z",
     "shell.execute_reply": "2023-06-03T13:55:09.679880Z",
     "shell.execute_reply.started": "2023-06-03T13:54:48.977457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/torcheval/torcheval/\n",
      "Processing /kaggle/input/torcheval/torcheval/torcheval-0.0.6-py3-none-any.whl\n",
      "Processing /kaggle/input/torcheval/torcheval/torchtnt-0.1.0-py3-none-any.whl (from torcheval)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.5.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (1.23.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2023.5.0)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2.12.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (5.9.3)\n",
      "Processing /kaggle/input/torcheval/torcheval/pyre_extensions-0.0.30-py3-none-any.whl (from torchtnt>=0.0.5->torcheval)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (59.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (4.64.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->torchtnt>=0.0.5->torcheval) (3.0.9)\n",
      "Requirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from pyre-extensions->torchtnt>=0.0.5->torcheval) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n",
      "Installing collected packages: pyre-extensions, torchtnt, torcheval\n",
      "Successfully installed pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import pywt\n",
    "from math import ceil\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import re\n",
    "from typing import Iterable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "!pip install torcheval --no-index --find-links=file:///kaggle/input/torcheval/torcheval/\n",
    "from torcheval.metrics import MulticlassAUPRC\n",
    "from torcheval.metrics import BinaryAUPRC\n",
    "#import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.689876Z",
     "iopub.status.busy": "2023-06-03T13:55:09.686984Z",
     "iopub.status.idle": "2023-06-03T13:55:09.738146Z",
     "shell.execute_reply": "2023-06-03T13:55:09.737081Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.689832Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    datasets_folder = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n",
    "    step_data_folder = '/kaggle/input/step-data/features/'\n",
    "    working_folder = '/kaggle/working/'\n",
    "    tdcs_features_ds_folder = '/kaggle/input/tdcs-steps/kaggle/working/features/'\n",
    "    data_names = ('tdcsfog', 'defog')\n",
    "    #saved_features_file = '.csv'\n",
    "    frequencies = (128, 100)\n",
    "    g = 9.806\n",
    "\n",
    "    batch_size = 1\n",
    "    num_workers = 8\n",
    "    \n",
    "    feature_window_size = 128\n",
    "    \n",
    "    window_size = 512\n",
    "    window_front = 96\n",
    "    window_back = 96\n",
    "    window_body = window_size - window_front - window_back\n",
    "    #window_future = 8\n",
    "    #window_past = window_size - window_future\n",
    "    \n",
    "    model_dropout = 0.1\n",
    "    model_nlayers = 4\n",
    "    model_middles = [16, 12, 8, 4]\n",
    "    model_nblocks = 4\n",
    "    model_layers_grow = 0\n",
    "    \n",
    "    #lr = 0.00015\n",
    "    lr = 0.00002\n",
    "    num_epochs_per_turn = 20\n",
    "    num_turns = 3\n",
    "    eval_freq = 5\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    feature_list = ['acc_v', 'acc_ml', 'acc_ap']\n",
    "    nfeatures = len(feature_list)\n",
    "    label_list_full = ['start_hesitation', 'turn', 'walking']\n",
    "    label_list = label_list_full\n",
    "    #label_list = ['walking']\n",
    "    #label_list = ['start_hesitation']\n",
    "    #label_list = ['start_hesitation', 'walking']\n",
    "    nlabels = len(label_list)\n",
    "    \n",
    "    load_model_from_file = False\n",
    "    model_file = '/kaggle/input/model-state-02/model_state_02.h5'\n",
    "    \n",
    "cfg = Config()\n",
    "#cfg.lr = 0.00003\n",
    "#cfg.model_dropout = 0.1\n",
    "#cfg.num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.747109Z",
     "iopub.status.busy": "2023-06-03T13:55:09.743771Z",
     "iopub.status.idle": "2023-06-03T13:55:09.760908Z",
     "shell.execute_reply": "2023-06-03T13:55:09.759670Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.747073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.769752Z",
     "iopub.status.busy": "2023-06-03T13:55:09.767455Z",
     "iopub.status.idle": "2023-06-03T13:55:09.784896Z",
     "shell.execute_reply": "2023-06-03T13:55:09.783827Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.769719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers [49 49 49 49]\n",
      "zero is correct 0\n"
     ]
    }
   ],
   "source": [
    "def make_layers( nl = cfg.model_nlayers, grow = cfg.model_layers_grow ):\n",
    "    base = (cfg.window_front + cfg.window_back - grow * nl * (nl+1)//2)//nl\n",
    "    layers_list = np.array([1 + base + (i+1)*grow for i in range(nl)])\n",
    "    layers_list = layers_list + 1 - np.divmod(layers_list, 2)[1]\n",
    "    layers_list[-1] = cfg.window_front + cfg.window_back + nl - sum(layers_list[0:-1])\n",
    "    print('layers', layers_list)\n",
    "    print('zero is correct', sum(layers_list)- nl - cfg.window_front - cfg.window_back)\n",
    "    return layers_list\n",
    "cfg.layers = make_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.793094Z",
     "iopub.status.busy": "2023-06-03T13:55:09.790711Z",
     "iopub.status.idle": "2023-06-03T13:55:09.806014Z",
     "shell.execute_reply": "2023-06-03T13:55:09.804192Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.793060Z"
    }
   },
   "outputs": [],
   "source": [
    "def camel_to_snake(name):\n",
    "    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n",
    "\n",
    "def read_data_file(test_id, subfolder_name = 'train/tdcsfog/'):\n",
    "    try:\n",
    "        data = pd.read_csv(cfg.datasets_folder+subfolder_name + str(test_id) + '.csv')\n",
    "    except:\n",
    "        return pd.NA\n",
    "    data.columns = [camel_to_snake(c) for c in data.columns]\n",
    "    return data\n",
    "\n",
    "def _find_binary(items: Iterable[int], item: int):\n",
    "    min = 0\n",
    "    max = len(items)-1\n",
    "    if items[max]<=item:\n",
    "        return max\n",
    "    while min<max:\n",
    "        split = (max+min)//2\n",
    "        item_split = items[split]\n",
    "        if item < item_split:\n",
    "            max = split\n",
    "        else:\n",
    "            min = split+1\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.814355Z",
     "iopub.status.busy": "2023-06-03T13:55:09.811890Z",
     "iopub.status.idle": "2023-06-03T13:55:09.839096Z",
     "shell.execute_reply": "2023-06-03T13:55:09.837597Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.814316Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_steps(signal, frequency=128, smoothing=2, faster_please=False, min_scale_log=3.6, max_scale_log=5.4):\n",
    "    \n",
    "    # scales for wavelets that define frequencies, exp for more even distribution\n",
    "    # choosing border values is tricky\n",
    "    # too narrow and we lose some slow or fast steprates\n",
    "    # too wide and we get the steprate wrong for unusual walking wavelet spectrum cases\n",
    "    # check patient #6 in the tdcsfog dataset as an example of an unusual pattern\n",
    "    scales = np.exp(np.arange(min_scale_log, max_scale_log, 0.05))\n",
    "    wavelet='morl'  # chosing the Morlet wavelet\n",
    "    \n",
    "    # transforming the signal, preferrably the 'AccMl' one\n",
    "    coeff, freq = pywt.cwt(signal, scales, wavelet)\n",
    "    # finding the brightest dots on every time slice\n",
    "    coeff_argmax_index = np.argmax(abs(coeff), 0)\n",
    "    # and collecting their coeff values in a new \"signal\", which already looks like our step rate, but is a bit noisy\n",
    "    coeff_max = np.array([coeff[coeff_argmax_index[i], i] for i in range(coeff.shape[1])])\n",
    "    \n",
    "    # repeating the smoothing procedure\n",
    "    for i in range(smoothing):\n",
    "        # transforming the noisy step rate again to clear it\n",
    "        coeff, freq = pywt.cwt(coeff_max, scales, wavelet)\n",
    "        # finding the brightest dots on every time slice\n",
    "        coeff_argmax_index = np.argmax(abs(coeff), 0).astype(int)\n",
    "        # and smoothing their indices with median to cut some outbursts off\n",
    "        coeff_argmax_index = np.round(pd.Series(coeff_argmax_index).rolling(128, center=True, min_periods=1).median()).astype(int)\n",
    "        # collecting the values along our line of indices\n",
    "        coeff_max = np.array([coeff[coeff_argmax_index[i], i] for i in range(coeff.shape[1])])\n",
    "    \n",
    "    # this smoothing round is optional\n",
    "    if not faster_please:\n",
    "        # finding hopefully bigger peaks on our line\n",
    "        # hopefully skiping too narrow or too close ones that are likely to be outbursts\n",
    "        max_cwt_points = sp.signal.find_peaks(abs(coeff_max), distance=20, width=20)[0]\n",
    "        max_cwt_points = np.concatenate(([0], max_cwt_points, [len(signal)-1]))\n",
    "        # and interpolating our line in wavelet space between the bigger peaks\n",
    "        max_cwt_line_indexes = np.round(np.interp( range(0, len(signal)), max_cwt_points, \n",
    "                                                    coeff_argmax_index[max_cwt_points])).astype(int)\n",
    "        coeff_max = np.array([coeff[max_cwt_line_indexes[i], i] for i in range(coeff.shape[1])])\n",
    "    \n",
    "    # finding zeroes on this smooth line to separate individual steps from other steps    \n",
    "    zero_crossings = np.where( np.diff(np.sign(pd.Series(coeff_max).rolling(10, center=True, min_periods=1).mean())))[0]\n",
    "    zero_crossings = np.concatenate( ([0], zero_crossings, [len(signal)]))    \n",
    "    #filling each step with its duration while cutting possible outbursts with median\n",
    "    step_lengths = []\n",
    "    for i in range(1, len(zero_crossings)):\n",
    "        step_lengths = np.concatenate( (step_lengths, [zero_crossings[i] - zero_crossings[i-1]]*(zero_crossings[i] - zero_crossings[i-1]) ))\n",
    "    step_durations = pd.Series(step_lengths).rolling(32, center=True, min_periods=1).median()\n",
    "    # making a nice and smooth step_rate array\n",
    "    step_rate = pd.Series( 1./step_durations )*frequency\n",
    "    step_rate = step_rate.where(step_rate<5, 0).rolling(frequency, center=True, min_periods=1).mean()\n",
    "    \n",
    "    return step_rate, step_durations/frequency, zero_crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.849047Z",
     "iopub.status.busy": "2023-06-03T13:55:09.845922Z",
     "iopub.status.idle": "2023-06-03T13:55:09.860345Z",
     "shell.execute_reply": "2023-06-03T13:55:09.859165Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.849010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#folder_path_tdcs = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/'\n",
    "# folder_path_defog = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/'\n",
    "#all_files_tdcs = [file for file in os.listdir(folder_path_tdcs)]\n",
    "# all_files_defog = [file for file in os.listdir(folder_path_defog)]\n",
    "\n",
    "#df_tdcsfog = pd.DataFrame(all_files_tdcs, columns = ['id'])\n",
    "#df_tdcsfog['id'] = df_tdcsfog['id'].apply(lambda x: x.rsplit('.',1)[0])\n",
    "#df_tdcsfog['data'] = df_tdcsfog['id'].apply(read_data_file)\n",
    "\n",
    "#df_tdcsfog['fog'] = df_tdcsfog['data'].apply(lambda x: x[['walking', 'start_hesitation']].max().max())\n",
    "#train_ids, valid_ids = train_test_split(df_tdcsfog['id'], random_state=42, stratify = df_tdcsfog['fog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.868006Z",
     "iopub.status.busy": "2023-06-03T13:55:09.866165Z",
     "iopub.status.idle": "2023-06-03T13:55:09.875360Z",
     "shell.execute_reply": "2023-06-03T13:55:09.874371Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.867975Z"
    }
   },
   "outputs": [],
   "source": [
    "#os.mkdir('/features/')\n",
    "#os.mkdir('/features/zero_crossings/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.879282Z",
     "iopub.status.busy": "2023-06-03T13:55:09.877768Z",
     "iopub.status.idle": "2023-06-03T13:55:09.892342Z",
     "shell.execute_reply": "2023-06-03T13:55:09.891413Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.879115Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.working_folder = '/kaggle/working/'\n",
    "def make_feature_file(data_row):\n",
    "    #data = data_row['data']\n",
    "    step_rate, step_durations, zero_crossings = detect_steps(data_row['data']['acc_ml'])\n",
    "    data_row['data']['step_rate'] = step_rate\n",
    "    data_row['data']['step_durations'] = step_durations\n",
    "    data_row['data'].to_csv(cfg.working_folder + 'features/'+data_row['id']+'.csv')\n",
    "    pd.DataFrame(zero_crossings).to_csv(cfg.working_folder + 'features/zero_crossings/'+data_row['id']+'.csv')\n",
    "    \n",
    "\n",
    "#def make_feature_files(dataset):\n",
    "#    for data_row in tqdm(dataset):\n",
    "#        data = data_row['data']\n",
    "#        step_rate, step_durations, zero_crossings = detect_steps(data['acc_ml'])\n",
    "#        data_row['data']['steprate'] = step_rate\n",
    "#        data_row['data']['step_durations'] = step_durations\n",
    "#        data_row['data']['zero_crossings'] = zero_crossings\n",
    "#        data_row['data'].to_csv('features/'+data_row['id']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.907045Z",
     "iopub.status.busy": "2023-06-03T13:55:09.901491Z",
     "iopub.status.idle": "2023-06-03T13:55:09.915253Z",
     "shell.execute_reply": "2023-06-03T13:55:09.914202Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.907014Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.923525Z",
     "iopub.status.busy": "2023-06-03T13:55:09.921086Z",
     "iopub.status.idle": "2023-06-03T13:55:09.933020Z",
     "shell.execute_reply": "2023-06-03T13:55:09.931905Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.923490Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_model(model_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{model_name}.zip\"\n",
    "    command = f\"zip {zip_name} {model_name}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{model_name}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.942154Z",
     "iopub.status.busy": "2023-06-03T13:55:09.939275Z",
     "iopub.status.idle": "2023-06-03T13:55:09.967870Z",
     "shell.execute_reply": "2023-06-03T13:55:09.966842Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.942123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='best_model_state_02.h5.zip' target='_blank'>best_model_state_02.h5.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/best_model_state_02.h5.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#download_file('/kaggle/working/features/', 'features.zip')\n",
    "download_model('best_model_state_02.h5')\n",
    "#download_file('/kaggle/working/features/', 'features.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.969487Z",
     "iopub.status.busy": "2023-06-03T13:55:09.969015Z",
     "iopub.status.idle": "2023-06-03T13:55:09.976527Z",
     "shell.execute_reply": "2023-06-03T13:55:09.974838Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.969456Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#make_feature_files(df_tdcsfog)\n",
    "#try:\n",
    "#    os.mkdir(cfg.working_folder + 'features/')\n",
    "#    os.mkdir(cfg.working_folder + 'features/zero_crossings/')\n",
    "#except: \n",
    "#    pass\n",
    "\n",
    "#df_tdcsfog.apply(make_feature_file, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:09.978724Z",
     "iopub.status.busy": "2023-06-03T13:55:09.978103Z",
     "iopub.status.idle": "2023-06-03T13:55:10.016571Z",
     "shell.execute_reply": "2023-06-03T13:55:10.015458Z",
     "shell.execute_reply.started": "2023-06-03T13:55:09.978691Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.wavelet_scales = np.exp(np.arange(2, 6, 0.5))\n",
    "cfg.wavelet_list = [ f'wave_{scale}' for scale in cfg.wavelet_scales ] \n",
    "cfg.wavelet='morl'\n",
    "#wavelet='shan'\n",
    "\n",
    "def make_features_train(data):\n",
    "    mean_center = True\n",
    "    rolling_window_size = cfg.feature_window_size\n",
    "    data['acc_ml_abs_rolling_mean'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_ml_abs_rolling_min'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).min()\n",
    "    data['acc_ml_abs_rolling_max'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).max()\n",
    "    data['acc_apv'] = (data['acc_ap']**2 + data['acc_v']**2)**0.5 - 9.806\n",
    "    data['acc_apv_rolling_mean'] = abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_apv_rolling_delta'] = abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).max() -\\\n",
    "        abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).min()\n",
    "    data['angle'] = data['acc_ap'] / data['acc_v'].rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['angle_rolling_mean'] = data['angle'].rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_v'] = data['acc_v']/3\n",
    "    \n",
    "    coeff, freq = pywt.cwt(data['acc_ml'], cfg.wavelet_scales, cfg.wavelet)\n",
    "    for i, scale in enumerate(cfg.wavelet_scales):\n",
    "        data[f'wave_{scale}'] = coeff[i] \n",
    "    \n",
    "    coeff_argmax = pd.Series(freq[np.argmax(abs(coeff), 0)]*cfg.frequencies[0])\\\n",
    "        .rolling(50, center=mean_center, min_periods=1).median().rolling(50, center=mean_center, min_periods=1).max()\n",
    "    data['coeff_argmax'] = coeff_argmax\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def make_features(data):\n",
    "    data = make_features_train(data)\n",
    "    \n",
    "    step_rate, step_durations, zero_crossings = detect_steps(data['acc_ml'])\n",
    "    data['steprate'] = step_rate\n",
    "    data['step_durations'] = step_durations\n",
    "    return data\n",
    "    \n",
    "\n",
    "def make_features_row(data_row, df_name):\n",
    "    data = data_row['data']\n",
    "    mean_center = True\n",
    "    rolling_window_size = rolling_window_size = cfg.feature_window_size\n",
    "    data['acc_ml_abs_rolling_mean'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_ml_abs_rolling_min'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).min()\n",
    "    data['acc_ml_abs_rolling_max'] = abs(data['acc_ml']).rolling(rolling_window_size, center=mean_center, min_periods=1).max()\n",
    "    #data['steprate'] = abs(data['acc_ml']).rolling(128, center=True, min_periods=1).max()\n",
    "    data['acc_apv'] = (data['acc_ap']**2 + data['acc_v']**2)**0.5 - 9.806\n",
    "    data['acc_apv_rolling_mean'] = abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_apv_rolling_delta'] = abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).max() -\\\n",
    "        abs(data['acc_apv']).rolling(rolling_window_size, center=mean_center, min_periods=1).min()\n",
    "    data['angle'] = data['acc_ap'] / data['acc_v'].rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['angle_rolling_mean'] = data['angle'].rolling(rolling_window_size, center=mean_center, min_periods=1).mean()\n",
    "    data['acc_v'] = data['acc_v']/3\n",
    "    #data['acc_ap'] = data['acc_ap']\n",
    "    tmp_df = pd.read_csv(cfg.tdcs_features_ds_folder + data_row['id'] + '.csv')\n",
    "    data = data.join(tmp_df[['steprate', 'step_durations']])\n",
    "    \n",
    "    scales = np.exp(np.arange(2, 6, 0.5))\n",
    "    wavelet='morl'\n",
    "    #wavelet='shan'\n",
    "    coeff, freq = pywt.cwt(data['acc_ml'], scales, wavelet)\n",
    "    cfg.wavelet_list = []\n",
    "    for i, scale in enumerate(scales):\n",
    "        data[f'wave_{scales}'] = coeff[i]\n",
    "        cfg.wavelet_list.append(f'wave_{scales}')\n",
    "    coeff_argmax = pd.Series(freq[np.argmax(abs(coeff), 0)]*cfg.frequencies[0])\\\n",
    "        .rolling(50, center=mean_center, min_periods=1).median().rolling(50, center=mean_center, min_periods=1).max()\n",
    "    data['coeff_argmax'] = coeff_argmax\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:10.024481Z",
     "iopub.status.busy": "2023-06-03T13:55:10.021715Z",
     "iopub.status.idle": "2023-06-03T13:55:10.034608Z",
     "shell.execute_reply": "2023-06-03T13:55:10.033509Z",
     "shell.execute_reply.started": "2023-06-03T13:55:10.024447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#df_tdcsfog['data'] = df_tdcsfog.apply(make_features_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:10.039903Z",
     "iopub.status.busy": "2023-06-03T13:55:10.039266Z",
     "iopub.status.idle": "2023-06-03T13:55:10.048759Z",
     "shell.execute_reply": "2023-06-03T13:55:10.047833Z",
     "shell.execute_reply.started": "2023-06-03T13:55:10.039872Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.feature_list = [\n",
    "    #'acc_v',           doesn't help\n",
    "    'acc_ml', \n",
    "    #'acc_ap',\n",
    "    'acc_ml_abs_rolling_mean',\n",
    "    'acc_ml_abs_rolling_min',\n",
    "    'acc_ml_abs_rolling_max',\n",
    "    'acc_apv',\n",
    "    'acc_apv_rolling_mean',\n",
    "    'acc_apv_rolling_delta',\n",
    "    #'angle',\n",
    "    'angle_rolling_mean',\n",
    "    'step_rate',\n",
    " #   'step_durations', doesn't help - maybe they were just too big\n",
    " #   'coeff_argmax'    doesn't help\n",
    "] + cfg.wavelet_list\n",
    "\n",
    "cfg.nfeatures = len(cfg.feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:10.053445Z",
     "iopub.status.busy": "2023-06-03T13:55:10.052672Z",
     "iopub.status.idle": "2023-06-03T13:55:10.089978Z",
     "shell.execute_reply": "2023-06-03T13:55:10.088718Z",
     "shell.execute_reply.started": "2023-06-03T13:55:10.053412Z"
    }
   },
   "outputs": [],
   "source": [
    "class cDataHolder():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def make_fog_class(self, row):\n",
    "        if ( row['fog_walking'] == 0 ) and ( row['fog_start_hesitation'] == 0 ):\n",
    "            fog_class = 'fog_no_complex'\n",
    "        elif ( row['fog_walking'] == 0 ) and ( row['fog_start_hesitation'] < 2500 ):\n",
    "            fog_class = 'fog_some_hesitation'\n",
    "        elif ( row['fog_walking'] < 2500) and ( row['fog_start_hesitation'] == 0 ):\n",
    "            fog_class = 'fog_some_walking'\n",
    "        elif ( row['fog_walking'] >= 2500):\n",
    "            fog_class = 'fog_bad_walking'\n",
    "        elif ( row['fog_start_hesitation'] >= 2500 ):\n",
    "            fog_class = 'fog_bad_hesitation'\n",
    "        else:\n",
    "            fog_class = 'fog_some_complex'\n",
    "        return fog_class\n",
    "    \n",
    "    def prepare_data_row(self, data_id, ds_name):\n",
    "        ds_name = ds_name + '/'\n",
    "        file_df = pd.read_csv(cfg.datasets_folder + 'train/' + ds_name + data_id +'.csv')\n",
    "        file_df.columns = [camel_to_snake(c) for c in file_df.columns]\n",
    "        steps_df = pd.read_csv(cfg.step_data_folder + ds_name + data_id +'.csv')\n",
    "        file_df = file_df.join(steps_df)\n",
    "        # ----------------- rescale time here\n",
    "        \n",
    "        file_df = make_features_train(file_df)\n",
    "        self.list_x.append(file_df[cfg.feature_list].values)\n",
    "        self.list_y.append(file_df[cfg.label_list].values)\n",
    "        return len(self.list_x)-1\n",
    "    \n",
    "    def load_train_data(self):\n",
    "        folder_path_tdcs = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog/'\n",
    "        all_files_tdcs = [file for file in os.listdir(folder_path_tdcs)]\n",
    "        self.df_tdcs = pd.DataFrame(all_files_tdcs, columns = ['id'])\n",
    "        self.df_tdcs['id'] = self.df_tdcs['id'].apply(lambda x: x.rsplit('.',1)[0])\n",
    "        \n",
    "        self.list_x, self.list_y = [], []\n",
    "        \n",
    "        for index, row in tqdm(self.df_tdcs.iterrows()):\n",
    "            #self.df_tdcs['main_index'][index] = \n",
    "            self.prepare_data_row(row['id'], 'tdcsfog')\n",
    "        \n",
    "        self.df_tdcs['tdcs'] = True\n",
    "        self.df = self.df_tdcs.copy()\n",
    "        \n",
    "        folder_path_defog = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog/'\n",
    "        all_files_defog = [file for file in os.listdir(folder_path_tdcs)]\n",
    "        self.df_defog = pd.DataFrame(all_files_defog, columns = ['id'])\n",
    "        self.df_defog['id'] = self.df_defog['id'].apply(lambda x: x.rsplit('.',1)[0])\n",
    "        \n",
    "        for index, label in enumerate(cfg.label_list):\n",
    "            dataholder.df['fog_'+label] = dataholder.df.reset_index()['index'].apply( lambda x: dataholder.list_y[x][:,index].sum())\n",
    "            \n",
    "        self.df['fog_class'] = self.df.apply(self.make_fog_class, axis=1)\n",
    "            \n",
    "        \n",
    "    def prepare_train_valid(self, complex_mult=10):    \n",
    "        self.train_nums, self.valid_nums = train_test_split(self.df.index, stratify = self.df['fog_class'])\n",
    "        df_train = self.df.loc[self.train_nums]['fog_class']\n",
    "        df_complex = df_train[df_train!='fog_no_complex']\n",
    "        df_fog = df_train[df_train=='fog_no_complex']\n",
    "        #print(len(df_fog), len(df_complex))\n",
    "        for i in range(10):\n",
    "            df_fog = df_fog.append(df_complex)            \n",
    "        self.train_nums = df_fog.sample(frac=1).index\n",
    "    \n",
    "    def get_data(self, index, add_zeros = True):\n",
    "        x = self.list_x[index]\n",
    "        y = self.list_y[index]\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "            \n",
    "        x = torch.tensor(x).to(torch.float32)\n",
    "        y = torch.Tensor(np.argmax(y,axis=1)).to(torch.int64)\n",
    "        return x, y\n",
    "        \n",
    "    def __getitem__(self, index, is_train, add_zeros = True):\n",
    "        file_index = self.train_nums[index] if is_train else self.valid_nums[index]\n",
    "        return self.get_data(file_index)\n",
    "    \n",
    "    def get_file_batch(self, file_index, add_zeros = True, want_valid = False):\n",
    "        return  self.__getitem__(self, file_index, not want_valid, add_zeros)\n",
    "    \n",
    "    def get_file_batch_id(self, file_id, add_zeros = True):\n",
    "        file_index = self.df[ self.df['id']==file_id ].index[0]\n",
    "        return self.get_data(file_index)\n",
    "    \n",
    "    def make_file_batch(self, file_data, add_zeros = True, with_targets=False):\n",
    "        x = file_data[cfg.feature_list].values\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "        x = torch.tensor(x).to(torch.float32).view(1, -1, cfg.nfeatures)\n",
    "        return x\n",
    "    \n",
    "dataholder = cDataHolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:10.093197Z",
     "iopub.status.busy": "2023-06-03T13:55:10.092291Z",
     "iopub.status.idle": "2023-06-03T13:55:10.099217Z",
     "shell.execute_reply": "2023-06-03T13:55:10.098297Z",
     "shell.execute_reply.started": "2023-06-03T13:55:10.093165Z"
    }
   },
   "outputs": [],
   "source": [
    "def __getitem__(holder, index, is_train, add_zeros = True):\n",
    "    file_index = dataholder.train_nums[index] if is_train else dataholder.valid_nums[index]\n",
    "    return dataholder.get_data(file_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:55:10.101901Z",
     "iopub.status.busy": "2023-06-03T13:55:10.101060Z",
     "iopub.status.idle": "2023-06-03T13:56:08.267102Z",
     "shell.execute_reply": "2023-06-03T13:56:08.266176Z",
     "shell.execute_reply.started": "2023-06-03T13:55:10.101867Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "833it [00:58, 14.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dataholder.load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:08.268966Z",
     "iopub.status.busy": "2023-06-03T13:56:08.268608Z",
     "iopub.status.idle": "2023-06-03T13:56:08.288364Z",
     "shell.execute_reply": "2023-06-03T13:56:08.287456Z",
     "shell.execute_reply.started": "2023-06-03T13:56:08.268933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706 127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fog_no_complex         706\n",
       "fog_some_hesitation    470\n",
       "fog_some_walking       330\n",
       "fog_some_complex       190\n",
       "fog_bad_hesitation     150\n",
       "fog_bad_walking        130\n",
       "Name: fog_class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_simple = self.df[self.df['fog_class']=='fog_no_complex']\n",
    "df_complex = dataholder.df[dataholder.df['fog_class']!='fog_no_complex']['fog_class']\n",
    "df_fog = dataholder.df[dataholder.df['fog_class']=='fog_no_complex']['fog_class']\n",
    "print(len(df_fog), len(df_complex))\n",
    "for i in range(10):\n",
    "    df_fog = df_fog.append(df_complex)\n",
    "\n",
    "df_fog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:08.290787Z",
     "iopub.status.busy": "2023-06-03T13:56:08.289811Z",
     "iopub.status.idle": "2023-06-03T13:56:08.303523Z",
     "shell.execute_reply": "2023-06-03T13:56:08.302569Z",
     "shell.execute_reply.started": "2023-06-03T13:56:08.290742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      fog_no_complex\n",
       "1      fog_no_complex\n",
       "2      fog_no_complex\n",
       "3      fog_no_complex\n",
       "4      fog_no_complex\n",
       "            ...      \n",
       "828    fog_no_complex\n",
       "829    fog_no_complex\n",
       "830    fog_no_complex\n",
       "831    fog_no_complex\n",
       "832    fog_no_complex\n",
       "Name: fog_class, Length: 1976, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fog.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:01:23.077625Z",
     "iopub.status.busy": "2023-06-03T14:01:23.076922Z",
     "iopub.status.idle": "2023-06-03T14:01:23.090923Z",
     "shell.execute_reply": "2023-06-03T14:01:23.089887Z",
     "shell.execute_reply.started": "2023-06-03T14:01:23.077591Z"
    }
   },
   "outputs": [],
   "source": [
    "dataholder.prepare_train_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.354354Z",
     "iopub.status.busy": "2023-06-03T13:56:20.354099Z",
     "iopub.status.idle": "2023-06-03T13:56:20.406224Z",
     "shell.execute_reply": "2023-06-03T13:56:20.405197Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.354332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      a171e618404171ea3a0c0f985a84405d320ade20ae8c67...\n",
       "tdcs                                                                  833\n",
       "fog_start_hesitation                                               304790\n",
       "fog_turn                                                          1678782\n",
       "fog_walking                                                        207838\n",
       "fog_class               fog_no_complexfog_no_complexfog_no_complexfog_...\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for index, row in tqdm(dataholder.df.iterrows()):\n",
    "#            row['fog'] = dataholder.list_y[cfg.label_list.index('walking')].sum()\n",
    "#label_list[1]\n",
    "for index, label in enumerate(cfg.label_list):\n",
    "    dataholder.df['fog_'+label] = dataholder.df.reset_index()['index'].apply( lambda x: dataholder.list_y[x][:,index].sum())\n",
    "#dataholder.df['walking_fog'] = dataholder.df.reset_index()['index'].apply( lambda x: dataholder.list_y[x][:,cfg.label_list.index('turn')].sum())\n",
    "dataholder.df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.408552Z",
     "iopub.status.busy": "2023-06-03T13:56:20.408204Z",
     "iopub.status.idle": "2023-06-03T13:56:20.882607Z",
     "shell.execute_reply": "2023-06-03T13:56:20.881232Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.408520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataholder.df['fog_walking'][dataholder.df['fog_walking']>0].hist(bins=100, figsize=(18,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.885157Z",
     "iopub.status.busy": "2023-06-03T13:56:20.884775Z",
     "iopub.status.idle": "2023-06-03T13:56:20.892559Z",
     "shell.execute_reply": "2023-06-03T13:56:20.891362Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.885122Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_fog_class(row):\n",
    "    if ( row['fog_walking'] == 0 ) and ( row['fog_start_hesitation'] == 0 ):\n",
    "        fog_class = 'fog_no_complex'\n",
    "    elif ( row['fog_walking'] == 0 ) and ( row['fog_start_hesitation'] < 2500 ):\n",
    "        fog_class = 'fog_some_hesitation'\n",
    "    elif ( row['fog_walking'] < 2500) and ( row['fog_start_hesitation'] == 0 ):\n",
    "        fog_class = 'fog_some_walking'\n",
    "    elif ( row['fog_walking'] >= 2500):\n",
    "        fog_class = 'fog_bad_walking'\n",
    "    elif ( row['fog_start_hesitation'] >= 2500 ):\n",
    "        fog_class = 'fog_bad_hesitation'\n",
    "    else:\n",
    "        fog_class = 'fog_some_complex'\n",
    "    return fog_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.895064Z",
     "iopub.status.busy": "2023-06-03T13:56:20.894108Z",
     "iopub.status.idle": "2023-06-03T13:56:20.922490Z",
     "shell.execute_reply": "2023-06-03T13:56:20.921304Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.895031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fog_no_complex         706\n",
       "fog_some_hesitation     47\n",
       "fog_some_walking        33\n",
       "fog_some_complex        19\n",
       "fog_bad_hesitation      15\n",
       "fog_bad_walking         13\n",
       "Name: fog_class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataholder.df['fog_class'] = dataholder.df.apply(make_fog_class, axis=1)\n",
    "dataholder.df['fog_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.926162Z",
     "iopub.status.busy": "2023-06-03T13:56:20.925678Z",
     "iopub.status.idle": "2023-06-03T13:56:20.934937Z",
     "shell.execute_reply": "2023-06-03T13:56:20.933980Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.926131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataholder.df['fog_start_hesitation'][dataholder.df['fog_start_hesitation']>100].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:56:20.936631Z",
     "iopub.status.busy": "2023-06-03T13:56:20.936200Z",
     "iopub.status.idle": "2023-06-03T13:57:06.932295Z",
     "shell.execute_reply": "2023-06-03T13:57:06.931331Z",
     "shell.execute_reply.started": "2023-06-03T13:56:20.936598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "833it [00:45, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.8 s, sys: 499 ms, total: 44.3 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#dataholder.load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:06.938961Z",
     "iopub.status.busy": "2023-06-03T13:57:06.936733Z",
     "iopub.status.idle": "2023-06-03T13:57:06.950343Z",
     "shell.execute_reply": "2023-06-03T13:57:06.947320Z",
     "shell.execute_reply.started": "2023-06-03T13:57:06.938928Z"
    }
   },
   "outputs": [],
   "source": [
    "class cFOGDataset_for_dataholder(Dataset):\n",
    "    def __init__(self, is_train=True, split=\"train\"):\n",
    "        self.is_train = is_train\n",
    "        self.split = split\n",
    "        return\n",
    "    def __len__(self):\n",
    "        return len(dataholder.train_nums) if self.is_train else len(dataholder.valid_nums)\n",
    "    def __getitem__(self, index, add_zeros = True):\n",
    "        return( dataholder.__getitem__(index, self.is_train, add_zeros) )\n",
    "    \n",
    "ds_train = cFOGDataset_for_dataholder(is_train=True, split = 'train')\n",
    "ds_valid = cFOGDataset_for_dataholder(is_train=False, split = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:06.953003Z",
     "iopub.status.busy": "2023-06-03T13:57:06.952090Z",
     "iopub.status.idle": "2023-06-03T13:57:06.995574Z",
     "shell.execute_reply": "2023-06-03T13:57:06.994672Z",
     "shell.execute_reply.started": "2023-06-03T13:57:06.952968Z"
    }
   },
   "outputs": [],
   "source": [
    "class cFOGDataset_06(Dataset):\n",
    "    def __init__(self, init_data, is_train=True, split=\"train\"):\n",
    "        self.df = init_data.loc[:, init_data.columns != 'data']\n",
    "        self.df['t_count'] = init_data['data'].apply(lambda x: x['time'].count())\n",
    "        self.df['window_count'] = np.ceil(self.df['t_count'] / cfg.window_body ).astype(int)\n",
    "        self.df['window_sum'] = self.df['window_count'].cumsum()\n",
    "        self.df['window_extra'] = self.df['window_count']*cfg.window_body - self.df['t_count']\n",
    "        self.is_train = is_train\n",
    "        self.split = split\n",
    "        self.list_x, self.list_y = [], []\n",
    "        for i in range(len(init_data)):\n",
    "            self.list_x.append(init_data.loc[i, 'data'][cfg.feature_list].values)\n",
    "            if is_train:\n",
    "                targets = init_data.loc[i, 'data'][cfg.label_list].values\n",
    "                self.list_y.append( np.concatenate([targets, (1 - targets.sum(axis=1)).reshape(-1,1)], axis=1) )  \n",
    "        \n",
    "    def __len__from_05(self):\n",
    "        return self.df['window_count'].sum()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df['window_count'].count()\n",
    "    \n",
    "    def get_index_y(self, index):\n",
    "        file_index = _find_binary(self.df['window_sum'], index)\n",
    "        infile_index = index if file_index==0 else index - self.df['window_sum'][file_index-1]\n",
    "        time_index = infile_index * cfg.window_body\n",
    "        return file_index, infile_index, time_index\n",
    "    \n",
    "    def get_file_batch(self, file_index, add_zeros = True):\n",
    "        x = self.list_x[file_index]\n",
    "        y = self.list_y[file_index]\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "        x = torch.tensor(x).to(torch.float32).view(1, -1, cfg.nfeatures)\n",
    "        y = torch.Tensor(np.argmax(y,axis=1)).to(torch.int64).view(1, -1)\n",
    "        return x, y, self.df.loc[file_index, 'id']\n",
    "    \n",
    "    def get_file_batch_id(self, file_id, add_zeros = True):\n",
    "        file_index = self.df[ self.df['id']==file_id ].index[0]\n",
    "        x = self.list_x[file_index]\n",
    "        y = self.list_y[file_index]\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "        x = torch.tensor(x).to(torch.float32).view(1, -1, cfg.nfeatures)\n",
    "        y = torch.Tensor(np.argmax(y,axis=1)).to(torch.int64).view(1, -1)\n",
    "        return x, y\n",
    "    \n",
    "    def make_file_batch(self, file_data, add_zeros = True, with_targets=False):\n",
    "        x = file_data[cfg.feature_list].values\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "        x = torch.tensor(x).to(torch.float32).view(1, -1, cfg.nfeatures)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, index, verbose = False, add_zeros = True):\n",
    "        x = self.list_x[index]\n",
    "        y = self.list_y[index]\n",
    "        if add_zeros:\n",
    "            x = np.concatenate(( np.zeros((cfg.window_front, x.shape[1])) , x, np.zeros((cfg.window_front, x.shape[1])) ))\n",
    "        x = torch.tensor(x).to(torch.float32)#.view(1, -1, cfg.nfeatures)\n",
    "        y = torch.Tensor(np.argmax(y,axis=1)).to(torch.int64)#.view(-1, 1)\n",
    "        return x, y\n",
    "    \n",
    "    def __getitem__from_05(self, index, verbose = False, add_zeros = True):\n",
    "        file_index = _find_binary(self.df['window_sum'], index)\n",
    "        infile_index = index if file_index==0 else index - self.df['window_sum'][file_index-1]\n",
    "        #time_index = infile_index * cfg.window_body - cfg.window_front\n",
    "        time_index = infile_index * cfg.window_body\n",
    "        x_index = time_index - cfg.window_front\n",
    "        front_zeros = 0\n",
    "        if x_index < 0:\n",
    "            front_zeros = -x_index\n",
    "            x_index = 0\n",
    "        \n",
    "        x = self.list_x[file_index][ x_index : x_index + cfg.window_size - front_zeros ]\n",
    "        y = self.list_y[file_index][ time_index : time_index + cfg.window_body ]\n",
    "        \n",
    "        rear_zeros = cfg.window_size - x.shape[0] - front_zeros\n",
    "        \n",
    "        if front_zeros or rear_zeros:\n",
    "            if add_zeros and front_zeros:\n",
    "                x = np.concatenate((np.zeros((front_zeros, x.shape[1])), x))\n",
    "            if add_zeros and rear_zeros:\n",
    "                x = np.concatenate((x, np.zeros((rear_zeros, x.shape[1]))))\n",
    "                if rear_zeros > cfg.window_back:\n",
    "                    y = np.concatenate((y, np.zeros((rear_zeros-cfg.window_back, y.shape[1]))))\n",
    "                    \n",
    "        if verbose:\n",
    "            print('file_index =', file_index)\n",
    "            print('window_count =', self.df.loc[file_index, 'window_count'])\n",
    "            print('window_sum =', self.df.loc[file_index, 'window_sum'])\n",
    "            if file_index>0:\n",
    "                print('window-1_sum =', self.df.loc[file_index-1, 'window_sum'])\n",
    "            print('t_count =', self.df.loc[file_index, 't_count'])\n",
    "            print('window_extra =', self.df.loc[file_index, 'window_extra'])\n",
    "            print('infile_index =', infile_index)\n",
    "            print('time_index =', time_index)  \n",
    "            print('x_index =', x_index)  \n",
    "            print('front_zeros =', front_zeros)\n",
    "            print('rear_zeros =', rear_zeros)\n",
    "            \n",
    "        x = torch.tensor(x).to(torch.float32)\n",
    "        y = torch.Tensor(np.argmax(y,axis=1)).to(torch.int64)\n",
    "        return x, y\n",
    "    \n",
    "#ds_train = cFOGDataset_06(df_tdcsfog.loc[train_ids.index].reset_index(drop=True), split = 'train')\n",
    "#ds_valid = cFOGDataset_06(df_tdcsfog.loc[valid_ids.index].reset_index(drop=True), split = 'valid')\n",
    "#ds_full = cFOGDataset_06(df_tdcsfog, split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:06.998660Z",
     "iopub.status.busy": "2023-06-03T13:57:06.997352Z",
     "iopub.status.idle": "2023-06-03T13:57:07.008094Z",
     "shell.execute_reply": "2023-06-03T13:57:07.007163Z",
     "shell.execute_reply.started": "2023-06-03T13:57:06.998627Z"
    }
   },
   "outputs": [],
   "source": [
    "#def make_a_batch(ds, index=0, batch_size = 8):\n",
    "#    xbatch = np.zeros((batch_size, cfg.window_size, cfg.nfeatures))\n",
    "#    ybatch = np.zeros((batch_size, cfg.window_body))\n",
    "#    for i in range(batch_size):\n",
    "#        item_x, item_y = ds.__getitem__(index+i)\n",
    "#        xbatch[i], ybatch[i] = item_x, item_y\n",
    "#    \n",
    "#    xbatch = torch.tensor(xbatch.astype(np.float32))\n",
    "#    ybatch = torch.tensor(ybatch).to(torch.int64)\n",
    "#    return xbatch, ybatch\n",
    "\n",
    "#def make_a_batch_05(ds, index=0, batch_size = 8):\n",
    "#    xbatch = np.zeros((batch_size, cfg.window_size, cfg.nfeatures))\n",
    "#    ybatch = np.zeros((batch_size, cfg.window_body))\n",
    "#    for i in range(batch_size):\n",
    "#        item_x, item_y = ds.__getitem__(index+i)\n",
    "#        xbatch[i], ybatch[i] = item_x, item_y\n",
    "#    \n",
    "#    xbatch = torch.tensor(xbatch.astype(np.float32))\n",
    "#    ybatch = torch.tensor(ybatch).to(torch.int64)\n",
    "#    return xbatch, ybatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.013593Z",
     "iopub.status.busy": "2023-06-03T13:57:07.012388Z",
     "iopub.status.idle": "2023-06-03T13:57:07.020204Z",
     "shell.execute_reply": "2023-06-03T13:57:07.019275Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.013556Z"
    }
   },
   "outputs": [],
   "source": [
    "#x01,y01gt = make_a_batch(ds_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.031675Z",
     "iopub.status.busy": "2023-06-03T13:57:07.029529Z",
     "iopub.status.idle": "2023-06-03T13:57:07.071938Z",
     "shell.execute_reply": "2023-06-03T13:57:07.069754Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.031642Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(cfg.model_dropout)\n",
    "conv1 = nn.Conv1d(cfg.nfeatures, 16, cfg.layers[0])\n",
    "conv2 = nn.Conv1d(16, 16, cfg.layers[1])\n",
    "conv3 = nn.Conv1d(16, 16, cfg.layers[2])\n",
    "conv4 = nn.Conv1d(16, 16, cfg.layers[3])\n",
    "linear = nn.Linear(16, cfg.nlabels+1)\n",
    "relu = nn.ReLU()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.073667Z",
     "iopub.status.busy": "2023-06-03T13:57:07.073291Z",
     "iopub.status.idle": "2023-06-03T13:57:07.083482Z",
     "shell.execute_reply": "2023-06-03T13:57:07.078194Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.073630Z"
    }
   },
   "outputs": [],
   "source": [
    "#file0 = ds_train.get_file_batch(0)\n",
    "#file0[1].shape\n",
    "#x = file0[0]\n",
    "#with torch.no_grad():\n",
    "#    y = model1.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.085224Z",
     "iopub.status.busy": "2023-06-03T13:57:07.084830Z",
     "iopub.status.idle": "2023-06-03T13:57:07.094984Z",
     "shell.execute_reply": "2023-06-03T13:57:07.093864Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.085189Z"
    }
   },
   "outputs": [],
   "source": [
    "#x = x01\n",
    "#x = x.to(torch.float)\n",
    "#print(x.shape)\n",
    "#x = x.transpose(1,2)\n",
    "#print(x.shape)\n",
    "#x = conv1(x)\n",
    "#print(x.shape)\n",
    "#x = conv2(x)\n",
    "#print(x.shape)\n",
    "#x = conv3(x)\n",
    "#print(x.shape)\n",
    "#x = conv4(x)\n",
    "#print(x.shape)\n",
    "#x = x.transpose(1,2)\n",
    "#print(x.shape)\n",
    "#x = x.view(-1,16)\n",
    "#print(x.shape)\n",
    "#x = linear(x)\n",
    "#print(x.shape)\n",
    "#x = softmax(x)\n",
    "#print(x.shape)\n",
    "#print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.097867Z",
     "iopub.status.busy": "2023-06-03T13:57:07.097152Z",
     "iopub.status.idle": "2023-06-03T13:57:07.123035Z",
     "shell.execute_reply": "2023-06-03T13:57:07.122033Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.097836Z"
    }
   },
   "outputs": [],
   "source": [
    "class FOGModel(nn.Module):\n",
    "    def __init__(self, p=cfg.model_dropout, nblocks=cfg.model_nblocks, layers_list = cfg.layers):\n",
    "        super(FOGModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.mid = cfg.model_middles\n",
    "        self.nlabels = cfg.nlabels\n",
    "        self.conv1 = nn.Conv1d(cfg.nfeatures, self.mid[0], layers_list[0])\n",
    "        self.conv2 = nn.Conv1d(self.mid[0], self.mid[1], layers_list[1])\n",
    "        self.conv3 = nn.Conv1d(self.mid[1], self.mid[2], layers_list[2])\n",
    "        self.conv4 = nn.Conv1d(self.mid[2], self.mid[3], layers_list[3])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(self.mid[3], cfg.nlabels+1)\n",
    "        #self.linear2 = nn.Linear(self.mid[3], cfg.nlabels+1)\n",
    "        #self.softmax = nn.Softmax(dim=2)\n",
    "        #self.softmax = F.log_softmax(dim=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(cfg.model_dropout)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.transpose(1,2)\n",
    "        x = self.linear1(x)\n",
    "        #x = self.relu(x)\n",
    "        \n",
    "        #x = self.linear2(x) \n",
    "        x = F.log_softmax(x, dim=2)\n",
    "        return x#[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.130998Z",
     "iopub.status.busy": "2023-06-03T13:57:07.128122Z",
     "iopub.status.idle": "2023-06-03T13:57:07.151282Z",
     "shell.execute_reply": "2023-06-03T13:57:07.150204Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.130961Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock_01(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dropout_rate):\n",
    "        super(ConvBlock_01, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.skip_offset = kernel_size//2\n",
    "\n",
    "        self.skip_connection = nn.Conv1d(in_channels, out_channels, kernel_size=1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "        self.identity = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.transpose(1, 2)\n",
    "        skip = self.skip_connection(x)\n",
    "        #skip = self.identity(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        #print('x:',x.shape, 'skip:', skip.shape, 'skip fixed:', skip[:,:,self.skip_offset:self.skip_offset+x.shape[2]].shape)\n",
    "        #skip = skip[:,:,self.skip_offset:self.skip_offset+x.shape[2]]\n",
    "        #print('x:',x.shape, 'skip:', skip.shape, 'skip fixed:', skip[:,:,self.skip_offset:self.skip_offset+x.shape[2]].shape)\n",
    "        #print('skip offset', self.skip_offset)     \n",
    "        x = self.batch_norm(x + skip[:,:,self.skip_offset:self.skip_offset+x.shape[2]])\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #x = x.transpose(1, 2)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class FOGModel_02(nn.Module):\n",
    "    def __init__(self, dropout_rate=cfg.model_dropout, in_channels=cfg.nfeatures, nblocks=cfg.model_nblocks, layers_list = cfg.layers):\n",
    "        super(FOGModel_02, self).__init__()\n",
    "        #self.dropout = nn.Dropout(p)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nblocks = cfg.model_nblocks\n",
    "        self.nlabels = cfg.nlabels\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = cfg.nlabels\n",
    "        self.mid = cfg.model_middles\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.mid[3], self.out_channels+1)\n",
    "        #self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[\n",
    "            ConvBlock_01(in_channels if i == 0 else self.mid[i-1], \n",
    "                      self.mid[i], \n",
    "                      layers_list[i], \n",
    "                      self.dropout_rate)\n",
    "            for i in range(nblocks)\n",
    "        ])       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.blocks(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.linear(x)\n",
    "        x = F.log_softmax(x) \n",
    "        return x#[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.160231Z",
     "iopub.status.busy": "2023-06-03T13:57:07.157340Z",
     "iopub.status.idle": "2023-06-03T13:57:07.167545Z",
     "shell.execute_reply": "2023-06-03T13:57:07.165651Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.160194Z"
    }
   },
   "outputs": [],
   "source": [
    "#model2 = FOGModel_02()\n",
    "#model1 = FOGModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.174939Z",
     "iopub.status.busy": "2023-06-03T13:57:07.172735Z",
     "iopub.status.idle": "2023-06-03T13:57:07.180380Z",
     "shell.execute_reply": "2023-06-03T13:57:07.179503Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.174907Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_loader = DataLoader(ds_train, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=True)\n",
    "#for batch in train_loader:\n",
    "#    xb, yb = batch\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.185475Z",
     "iopub.status.busy": "2023-06-03T13:57:07.184215Z",
     "iopub.status.idle": "2023-06-03T13:57:07.204271Z",
     "shell.execute_reply": "2023-06-03T13:57:07.199863Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.185444Z"
    }
   },
   "outputs": [],
   "source": [
    "#y1 = model2.forward(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.207077Z",
     "iopub.status.busy": "2023-06-03T13:57:07.206035Z",
     "iopub.status.idle": "2023-06-03T13:57:07.217629Z",
     "shell.execute_reply": "2023-06-03T13:57:07.216542Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.207026Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    loss_sum = 0.\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    model.train()\n",
    "    #for x,y in loader:        \n",
    "    for x,y in tqdm(loader):        \n",
    "        x = x.to(cfg.device)\n",
    "        y = y.to(cfg.device)\n",
    "\n",
    "       \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred.view(-1, y_pred.size(-1)), y.view(-1))           \n",
    "        \n",
    "        # loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        # optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()       \n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "    \n",
    "    print(f\"Train Loss: {(loss_sum/len(loader)):.04f}\")\n",
    "    return loss_sum/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.221835Z",
     "iopub.status.busy": "2023-06-03T13:57:07.220482Z",
     "iopub.status.idle": "2023-06-03T13:57:07.242599Z",
     "shell.execute_reply": "2023-06-03T13:57:07.241077Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.221779Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation_one_epoch(model, loader, criterion, metric):\n",
    "    loss_sum = 0.\n",
    "    y_true_epoch = torch.empty((0), dtype=torch.int64).to(cfg.device)\n",
    "    y_pred_epoch = torch.empty((0,cfg.nlabels), dtype=torch.float32).to(cfg.device)\n",
    "    #t_valid_epoch = []\n",
    "    \n",
    "    model.eval()\n",
    "    #for x,y in tqdm(loader):\n",
    "    for x,y in loader:\n",
    "        x = x.to(cfg.device)\n",
    "        y = y.to(cfg.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred.view(-1, y_pred.size(-1)), y.view(-1))\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        #print('cat', y_true_epoch.shape, y.view(-1, 1).shape)\n",
    "        y_true_epoch = torch.cat([y_true_epoch, y.view(-1, 1)])\n",
    "        #print('cat -----> y_pred_epoch:', y_pred_epoch.exp().shape, 'cat -----> y_pred:', y_pred.shape, \n",
    "        #      'cat -----> y_pred.view(-1, y_pred.size(-1)):', y_pred.view(-1, y_pred.size(-1)).shape)\n",
    "        y_pred = y_pred[:,:,:-1]\n",
    "        y_pred_epoch = torch.cat([y_pred_epoch, y_pred.view(-1, y_pred.size(-1))])\n",
    "    \n",
    "    #metric.update(y_pred_epoch, y_true_epoch.view(-1))\n",
    "    y_pred_2 = y_pred_epoch\n",
    "    \n",
    "    #average_precision_score()\n",
    "    #print('metric', y_pred_epoch.exp().shape, y_true_epoch.view(-1).shape)\n",
    "    if model.nlabels > 1:\n",
    "        metric.update(y_pred_epoch.exp(), y_true_epoch.view(-1))\n",
    "    else:\n",
    "        metric.update(y_pred_epoch.exp().view(-1), y_true_epoch.view(-1))\n",
    "    scores = metric.compute()\n",
    "    mean_score = scores.mean().cpu().numpy().item()\n",
    "    #print(scores)\n",
    "    #print(mean_score)\n",
    "    \n",
    "    #mask = torch.ones((1,cfg.nlabels), dtype=torch.float32).to(cfg.device)\n",
    "    #mask[0,cfg.nlabels-1] = 0\n",
    "    #metric.update(y_pred_epoch.exp()*mask, y_true_epoch.view(-1))\n",
    "    #score2 = metric.compute().mean()\n",
    "    \n",
    "    if model.nlabels == 3:\n",
    "        print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}, ClassWise: {scores[0]:.03f},{scores[1]:.03f},{scores[2]:.03f}\")    \n",
    "    elif model.nlabels == 2:\n",
    "        print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}, ClassWise: {scores[0]:.03f},{scores[1]:.03f}\")    \n",
    "    else:\n",
    "        print(f\"Validation Loss: {(loss_sum/len(loader)):.04f}, Validation Score: {mean_score:.03f}\")        \n",
    "    return mean_score, (loss_sum/len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.250015Z",
     "iopub.status.busy": "2023-06-03T13:57:07.247536Z",
     "iopub.status.idle": "2023-06-03T13:57:07.257702Z",
     "shell.execute_reply": "2023-06-03T13:57:07.256851Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.249983Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_file(model, file_data):   \n",
    "    model.eval()\n",
    "    x = dataholder.make_file_batch(file_data).to(cfg.device)\n",
    "    with torch.no_grad():\n",
    "        y = model.forward(x)\n",
    "    y = np.exp(y.cpu().numpy())\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.265098Z",
     "iopub.status.busy": "2023-06-03T13:57:07.262458Z",
     "iopub.status.idle": "2023-06-03T13:57:07.278411Z",
     "shell.execute_reply": "2023-06-03T13:57:07.277467Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.265065Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_validation_graph(index, model, want_valid = True, file_id=None):\n",
    "    if file_id==None:\n",
    "        x, y_true = dataholder.get_file_batch(index, want_valid=want_valid)\n",
    "    else:\n",
    "        x, y_true = dataholder.get_file_batch_id(file_id)\n",
    "    #get_file_batch(self, file_index, add_zeros = True, want_valid = False):\n",
    "    model.eval()\n",
    "    x = x.to(cfg.device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model.forward(x[None, :])\n",
    "    y_pred = np.exp(y_pred.cpu().numpy())\n",
    "    x = x.cpu().numpy()\n",
    "    \n",
    "    #tmpdf = pd.DataFrame(x, cfg.feature_list)\n",
    "    #tmpdf = df_tdcsfog[ df_tdcsfog['id']==file_id ]['data'].iloc[0]\n",
    "    result = pd.DataFrame( y_pred.reshape(-1, cfg.nlabels+1)[:,:cfg.nlabels], columns = cfg.label_list )\n",
    "    \n",
    "    figs, ax = plt.subplots(2,1, figsize=(18,5))\n",
    "    #tmpdf[['acc_v','acc_ml','acc_ap']].plot(ax=ax[0])\n",
    "    y_true_3 = np.zeros((y_true.shape[0], 4))\n",
    "    y_true_3[:,3 - y_true.numpy()] = 1\n",
    "    pd.DataFrame( y_true_3[:,:3], columns = [cfg.label_list] ).plot(ax=ax[0])\n",
    "    result.reset_index(drop=True).plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T13:57:07.286519Z",
     "iopub.status.busy": "2023-06-03T13:57:07.283754Z",
     "iopub.status.idle": "2023-06-03T13:57:07.344271Z",
     "shell.execute_reply": "2023-06-03T13:57:07.337830Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.286480Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my_true\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m y_true_3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m y_true_3[:,\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m-\u001b[39m y_true\u001b[38;5;241m.\u001b[39mnumpy()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "#y_true.numpy()\n",
    "#y_true_3 = np.zeros((y_true.shape[0], 4))\n",
    "#y_true_3[:,3 - y_true.numpy()] = 1\n",
    "#y_true_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.347373Z",
     "iopub.status.idle": "2023-06-03T13:57:07.349894Z",
     "shell.execute_reply": "2023-06-03T13:57:07.349631Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.349605Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = np.array([3, 3, 3, 2, 1, 3, 0, 3])\n",
    "y_true_3 = np.zeros((y_true.shape[0], 4))\n",
    "y_true_3\n",
    "np.put_along_axis(y_true_3, y_true[:,None], 1, axis=1)\n",
    "y_true_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.354148Z",
     "iopub.status.idle": "2023-06-03T13:57:07.356664Z",
     "shell.execute_reply": "2023-06-03T13:57:07.356417Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.356389Z"
    }
   },
   "outputs": [],
   "source": [
    "#p = zip(1,q)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.359873Z",
     "iopub.status.idle": "2023-06-03T13:57:07.363333Z",
     "shell.execute_reply": "2023-06-03T13:57:07.363087Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.363059Z"
    }
   },
   "outputs": [],
   "source": [
    "q = (3 - y_true.numpy()).astype(int)\n",
    "y_true_3 = np.zeros((y_true.shape[0], 4))\n",
    "#y_true_3[: q] = 1\n",
    "np.put_along_axis(y_true_3, q[:,None], 1, axis=0)\n",
    "y_true_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.364831Z",
     "iopub.status.idle": "2023-06-03T13:57:07.365632Z",
     "shell.execute_reply": "2023-06-03T13:57:07.365400Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.365375Z"
    }
   },
   "outputs": [],
   "source": [
    "q = (3 - y_true.numpy()).astype(int)\n",
    "y_true_3 = np.zeros((y_true.shape[0], 4))\n",
    "#y_true_3[: q] = 1\n",
    "y_true_3[np.arange(y_true_3.shape[1]) <= q[:, None]] = 0\n",
    "y_true_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.371700Z",
     "iopub.status.idle": "2023-06-03T13:57:07.372551Z",
     "shell.execute_reply": "2023-06-03T13:57:07.372295Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.372270Z"
    }
   },
   "outputs": [],
   "source": [
    "len(y_true_3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.374024Z",
     "iopub.status.idle": "2023-06-03T13:57:07.374835Z",
     "shell.execute_reply": "2023-06-03T13:57:07.374582Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.374557Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_validation_graph(3, model)\n",
    "#x, y_true = dataholder.get_file_batch(3, want_valid=True)\n",
    "#x.shape\n",
    "#y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.376283Z",
     "iopub.status.idle": "2023-06-03T13:57:07.377098Z",
     "shell.execute_reply": "2023-06-03T13:57:07.376857Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.376832Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = x.to(cfg.device)\n",
    "with torch.no_grad():\n",
    "    y_pred = model.forward(x[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.384621Z",
     "iopub.status.idle": "2023-06-03T13:57:07.385423Z",
     "shell.execute_reply": "2023-06-03T13:57:07.385193Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.385169Z"
    }
   },
   "outputs": [],
   "source": [
    "#validation_one_epoch(model, valid_loader, criterion, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.386885Z",
     "iopub.status.idle": "2023-06-03T13:57:07.387712Z",
     "shell.execute_reply": "2023-06-03T13:57:07.387471Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.387448Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "#weights = torch.tensor([0.5, 0.5, 0.5, 0.1])\n",
    "#criterion = torch.nn.CrossEntropyLoss().to(cfg.device)\n",
    "#metric = MulticlassAUPRC( num_classes=cfg.nlabels, average=None )\n",
    "#train_one_epoch(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T13:57:07.389262Z",
     "iopub.status.idle": "2023-06-03T13:57:07.390116Z",
     "shell.execute_reply": "2023-06-03T13:57:07.389880Z",
     "shell.execute_reply.started": "2023-06-03T13:57:07.389856Z"
    }
   },
   "outputs": [],
   "source": [
    "#cfg.lr = 0.00003\n",
    "#cfg.model_dropout = 0.1\n",
    "#cfg.num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:28.976579Z",
     "iopub.status.busy": "2023-06-03T14:00:28.976099Z",
     "iopub.status.idle": "2023-06-03T14:00:28.989037Z",
     "shell.execute_reply": "2023-06-03T14:00:28.988115Z",
     "shell.execute_reply.started": "2023-06-03T14:00:28.976542Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, ds_train, ds_valid, num_epochs = cfg.num_epochs_per_turn, eval_freq = 1):\n",
    "    #model = FOGModel_02().to(cfg.device)\n",
    "    #model = FOGModel().to(cfg.device)\n",
    "    #print(f\"Number of parameters in model - {count_parameters(model):,}\")\n",
    "\n",
    "    #print(f\"lengths of datasets: train - {len(train_dataset)}, valid - {len(valid_dataset)}\")\n",
    "\n",
    "    train_loader = DataLoader(ds_train, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=True)\n",
    "    valid_loader = DataLoader(ds_valid, batch_size=cfg.batch_size, num_workers=cfg.num_workers)\n",
    "\n",
    "    #weights = torch.tensor([0.2, 0.3, 0.1, 0.5])\n",
    "    #criterion = torch.nn.CrossEntropyLoss(weight=weights, reduction='none').to(cfg.device)\n",
    "    #criterion = torch.nn.CrossEntropyLoss().to(cfg.device)\n",
    "    criterion = torch.nn.NLLLoss().to(cfg.device)\n",
    "    if cfg.nlabels > 1:\n",
    "        metric = MulticlassAUPRC( num_classes=cfg.nlabels, average=None )\n",
    "    else:\n",
    "        metric = BinaryAUPRC()\n",
    "    # sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.85)\n",
    "\n",
    "    max_score, score = 0.0, 0.0\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "\n",
    "        if (epoch % eval_freq == eval_freq-1) and ( eval_freq != -1):\n",
    "            score, val_loss = validation_one_epoch(model, valid_loader, criterion, metric)\n",
    "            train_log.append([ train_loss, val_loss, score])\n",
    "            #pd.DataFrame(train_log, columns=('Epoch', 'Train loss', 'Val loss', 'Val score')).plot()\n",
    "            print(\"=\"*50)\n",
    "        # sched.step()\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            #torch.save(model.state_dict(), \"best_model_state.h5\")\n",
    "            #print(\"Saving Model ...\")\n",
    "        \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:29.025669Z",
     "iopub.status.busy": "2023-06-03T14:00:29.025333Z",
     "iopub.status.idle": "2023-06-03T14:00:29.030003Z",
     "shell.execute_reply": "2023-06-03T14:00:29.028855Z",
     "shell.execute_reply.started": "2023-06-03T14:00:29.025645Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"best_model_state_01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:29.076483Z",
     "iopub.status.busy": "2023-06-03T14:00:29.076219Z",
     "iopub.status.idle": "2023-06-03T14:00:29.080329Z",
     "shell.execute_reply": "2023-06-03T14:00:29.079352Z",
     "shell.execute_reply.started": "2023-06-03T14:00:29.076460Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = FOGModel().to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:29.126034Z",
     "iopub.status.busy": "2023-06-03T14:00:29.125490Z",
     "iopub.status.idle": "2023-06-03T14:00:29.132353Z",
     "shell.execute_reply": "2023-06-03T14:00:29.131359Z",
     "shell.execute_reply.started": "2023-06-03T14:00:29.126002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2e-05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:01:39.068055Z",
     "iopub.status.busy": "2023-06-03T14:01:39.067091Z",
     "iopub.status.idle": "2023-06-03T14:01:39.076561Z",
     "shell.execute_reply": "2023-06-03T14:01:39.075218Z",
     "shell.execute_reply.started": "2023-06-03T14:01:39.068015Z"
    }
   },
   "outputs": [],
   "source": [
    "if not cfg.load_model_from_file:\n",
    "    #model = FOGModel_02().to(cfg.device)\n",
    "    model = FOGModel().to(cfg.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:31.884494Z",
     "iopub.status.busy": "2023-06-03T14:00:31.884141Z",
     "iopub.status.idle": "2023-06-03T14:00:31.890601Z",
     "shell.execute_reply": "2023-06-03T14:00:31.889553Z",
     "shell.execute_reply.started": "2023-06-03T14:00:31.884449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model, optimizer = train_model(model, optimizer, ds_train, ds_valid, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:01:41.276989Z",
     "iopub.status.busy": "2023-06-03T14:01:41.276490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big epoch 0\n",
      "==================================================\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:23<00:00, 63.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2548\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 101.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0182\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9216\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8451\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4316, Validation Score: 0.609, ClassWise: 0.971,0.727,0.128\n",
      "==================================================\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 99.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7173\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6618\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6140\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5751\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3014, Validation Score: 0.591, ClassWise: 0.974,0.704,0.094\n",
      "==================================================\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 95.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5305\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 98.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5191\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5110\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 99.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5047\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2802, Validation Score: 0.590, ClassWise: 0.975,0.711,0.085\n",
      "==================================================\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 101.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4926\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 97.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4900\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 99.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4855\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 96.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4826\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2641, Validation Score: 0.591, ClassWise: 0.974,0.716,0.082\n",
      "==================================================\n",
      "Big epoch 1\n",
      "==================================================\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 95.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4764\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4749\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 96.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4726\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 100.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4713\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:15<00:00, 96.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3124, Validation Score: 0.629, ClassWise: 0.977,0.729,0.180\n",
      "==================================================\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1479/1479 [00:14<00:00, 99.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4667\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 562/1479 [00:05<00:08, 103.02it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#num_epochs_per_turn = 20\n",
    "#num_turns = 5\n",
    "#eval_freq = 5\n",
    "train_log = []\n",
    "\n",
    "if not cfg.load_model_from_file:\n",
    "    for i in range(cfg.num_turns):\n",
    "        print('Big epoch', i)\n",
    "        model, optimizer = train_model(model, optimizer, ds_train, ds_valid, eval_freq = cfg.eval_freq, num_epochs = cfg.num_epochs_per_turn)\n",
    "        #model, optimizer = train_model(model, optimizer, ds_full, ds_valid, eval_freq = cfg.eval_freq, num_epochs = cfg.num_epochs_per_turn)        \n",
    "        \n",
    "pd.DataFrame(train_log, columns=('Train loss', 'Val loss', 'Val score')).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:32.218263Z",
     "iopub.status.busy": "2023-06-03T14:00:32.217819Z",
     "iopub.status.idle": "2023-06-03T14:00:32.222383Z",
     "shell.execute_reply": "2023-06-03T14:00:32.221476Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.218225Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"best_model_state.h5\", map_location=torch.device(cfg.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-03T14:00:32.224508Z",
     "iopub.status.busy": "2023-06-03T14:00:32.223822Z",
     "iopub.status.idle": "2023-06-03T14:00:32.264125Z",
     "shell.execute_reply": "2023-06-03T14:00:32.261992Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.224459Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_log\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_log[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.265305Z",
     "iopub.status.idle": "2023-06-03T14:00:32.265859Z",
     "shell.execute_reply": "2023-06-03T14:00:32.265571Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.265541Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.array(train_log)\n",
    "#.to('cpu').numpy()\n",
    "#for log in train_log:\n",
    "#    log[3] = log[3].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.266914Z",
     "iopub.status.idle": "2023-06-03T14:00:32.267335Z",
     "shell.execute_reply": "2023-06-03T14:00:32.267137Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.267117Z"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(train_log).plot(x='Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.268591Z",
     "iopub.status.idle": "2023-06-03T14:00:32.268996Z",
     "shell.execute_reply": "2023-06-03T14:00:32.268829Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.268789Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.load_model_from_file:\n",
    "    model = FOGModel()\n",
    "    model.load_state_dict(torch.load(cfg.model_file, map_location=torch.device(cfg.device)))\n",
    "    model.to(cfg.device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.270185Z",
     "iopub.status.idle": "2023-06-03T14:00:32.270616Z",
     "shell.execute_reply": "2023-06-03T14:00:32.270408Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.270386Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.272144Z",
     "iopub.status.idle": "2023-06-03T14:00:32.272836Z",
     "shell.execute_reply": "2023-06-03T14:00:32.272602Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.272580Z"
    }
   },
   "outputs": [],
   "source": [
    "test_folder_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/'\n",
    "test_files = [file for file in os.listdir(test_folder_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.274431Z",
     "iopub.status.idle": "2023-06-03T14:00:32.275132Z",
     "shell.execute_reply": "2023-06-03T14:00:32.274863Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.274834Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "for test_file in test_files:\n",
    "    test_df = pd.read_csv(test_folder_path + test_file) \n",
    "    test_df.columns = [camel_to_snake(c) for c in test_df.columns]\n",
    "    test_df = make_features(test_df)\n",
    "    #df_tdcsfog['id'] = df_tdcsfog['id'].apply(lambda x: x.rsplit('.',1)[0])\n",
    "    test_file_id = test_file.rsplit('.',1)[0]\n",
    "    pred = predict_file(model, test_df).reshape(-1,cfg.nlabels+1)\n",
    "    #pred = np\n",
    "    id_time = [f'{test_file_id}_{t}' for t in test_df['time']]\n",
    "    tmp = pd.DataFrame(pred[:,:cfg.nlabels], index=id_time)#.loc[[t != -1 for t in time]]\n",
    "    result = pd.concat([result, tmp])\n",
    "        \n",
    "result.columns = ['StartHesitation', 'Turn', 'Walking'][:cfg.nlabels]\n",
    "\n",
    "sample_submission = sample_submission.set_index('Id')\n",
    "sample_submission.update(result)\n",
    "sample_submission.reset_index().to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.276879Z",
     "iopub.status.idle": "2023-06-03T14:00:32.277682Z",
     "shell.execute_reply": "2023-06-03T14:00:32.277457Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.277428Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_validation_graph(2, ds_valid, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.281115Z",
     "iopub.status.idle": "2023-06-03T14:00:32.282009Z",
     "shell.execute_reply": "2023-06-03T14:00:32.281774Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.281752Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpdf = plot_validation_graph(3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.283232Z",
     "iopub.status.idle": "2023-06-03T14:00:32.284006Z",
     "shell.execute_reply": "2023-06-03T14:00:32.283777Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.283755Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpdf = plot_validation_graph(11, ds_valid, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.285663Z",
     "iopub.status.idle": "2023-06-03T14:00:32.286717Z",
     "shell.execute_reply": "2023-06-03T14:00:32.286503Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.286481Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = df_tdcsfog[df_tdcsfog['fog']>0].index\n",
    "ugly_ids = valid_ids[ valid_ids.index.isin(indices)]\n",
    "ugly_ids.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.287918Z",
     "iopub.status.idle": "2023-06-03T14:00:32.288980Z",
     "shell.execute_reply": "2023-06-03T14:00:32.288713Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.288692Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpdf = plot_validation_graph(11, ds_valid, model, file_id=ugly_ids.iloc[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.290196Z",
     "iopub.status.idle": "2023-06-03T14:00:32.290964Z",
     "shell.execute_reply": "2023-06-03T14:00:32.290724Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.290701Z"
    }
   },
   "outputs": [],
   "source": [
    "#os.listdir('/kaggle/working/')\n",
    "#os.listdir('/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.292467Z",
     "iopub.status.idle": "2023-06-03T14:00:32.293053Z",
     "shell.execute_reply": "2023-06-03T14:00:32.292846Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.292824Z"
    }
   },
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(2,1, figsize=(18,5))\n",
    "test_df[['acc_v','acc_ml','acc_ap']].plot(ax=ax[0])\n",
    "result.reset_index(drop=True).plot(ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-03T14:00:32.294687Z",
     "iopub.status.idle": "2023-06-03T14:00:32.295670Z",
     "shell.execute_reply": "2023-06-03T14:00:32.295418Z",
     "shell.execute_reply.started": "2023-06-03T14:00:32.295393Z"
    }
   },
   "outputs": [],
   "source": [
    "#x_slice = x[:, cfg.window_front:cfg.window_front+cfg.window_body ,:]\n",
    "#x_slice.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
